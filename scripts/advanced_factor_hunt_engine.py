#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Advanced Factor Hunt Engine - é«˜çº§å› å­æœç´¢å¼•æ“
ç³»ç»Ÿæ€§æµ‹è¯•å¤šç§ç±»å‹çš„é‡åŒ–å› å­ï¼Œå¯»æ‰¾çœŸæ­£æœ‰æ•ˆçš„ç­–ç•¥
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
from pathlib import Path
import logging
from typing import Dict, List, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from scripts.bias_free_backtest_engine import (
    BiasFreeBacktestEngine,
    SignalGenerator,
    TradingInstruction,
    DataSnapshot
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MomentumSignalGenerator(SignalGenerator):
    """åŠ¨é‡å› å­ä¿¡å·ç”Ÿæˆå™¨ - å¤šå‘¨æœŸåŠ¨é‡ç­–ç•¥"""

    def __init__(self, lookback_period: int = 20, momentum_threshold: float = 0.05):
        super().__init__(f"Momentum_{lookback_period}days_{momentum_threshold}")
        self.lookback_period = lookback_period
        self.momentum_threshold = momentum_threshold

    def generate_signals(self, snapshot: DataSnapshot) -> List[TradingInstruction]:
        instructions = []

        for stock_code, factors in snapshot.factor_data.items():
            if 'momentum_score' in factors and not pd.isna(factors['momentum_score']):
                momentum = factors['momentum_score']

                # æ­£å‘åŠ¨é‡ï¼šä¹°å…¥ä¸Šæ¶¨è‚¡ç¥¨
                if momentum > self.momentum_threshold:
                    instructions.append(TradingInstruction(
                        stock_code=stock_code,
                        action='BUY',
                        quantity=1000,
                        reason=f"Momentum: {momentum:.4f} > {self.momentum_threshold}",
                        timestamp=snapshot.date
                    ))

        return instructions

    @staticmethod
    def calculate_momentum(data: pd.DataFrame, lookback_period: int = 20) -> float:
        """è®¡ç®—åŠ¨é‡å› å­ï¼šè¿‡å»Nå¤©çš„æ”¶ç›Šç‡"""
        if len(data) < lookback_period + 1:
            return np.nan

        start_price = data['close'].iloc[-(lookback_period + 1)]
        end_price = data['close'].iloc[-1]

        momentum = (end_price - start_price) / start_price
        return momentum

class MeanReversionSignalGenerator(SignalGenerator):
    """å‡å€¼å›å½’å› å­ä¿¡å·ç”Ÿæˆå™¨ - åŸºäºç§»åŠ¨å‡å€¼çš„å›å½’ç­–ç•¥"""

    def __init__(self, lookback_period: int = 20, deviation_threshold: float = 2.0):
        super().__init__(f"MeanReversion_{lookback_period}days_{deviation_threshold}std")
        self.lookback_period = lookback_period
        self.deviation_threshold = deviation_threshold

    def generate_signals(self, snapshot: DataSnapshot) -> List[TradingInstruction]:
        instructions = []

        for stock_code, factors in snapshot.factor_data.items():
            if 'mean_reversion_score' in factors and not pd.isna(factors['mean_reversion_score']):
                reversion_score = factors['mean_reversion_score']

                # ä»·æ ¼ä½äºå‡å€¼è¿‡å¤šæ—¶ä¹°å…¥ï¼ˆå‡å€¼å›å½’ï¼‰
                if reversion_score < -self.deviation_threshold:
                    instructions.append(TradingInstruction(
                        stock_code=stock_code,
                        action='BUY',
                        quantity=1000,
                        reason=f"Mean Reversion: {reversion_score:.4f} < -{self.deviation_threshold}",
                        timestamp=snapshot.date
                    ))

        return instructions

    @staticmethod
    def calculate_mean_reversion(data: pd.DataFrame, lookback_period: int = 20) -> float:
        """è®¡ç®—å‡å€¼å›å½’å› å­ï¼šå½“å‰ä»·æ ¼ç›¸å¯¹äºç§»åŠ¨å‡å€¼çš„åç¦»åº¦"""
        if len(data) < lookback_period:
            return np.nan

        recent_prices = data['close'].iloc[-lookback_period:]
        current_price = data['close'].iloc[-1]

        mean_price = recent_prices.mean()
        std_price = recent_prices.std()

        if std_price > 0:
            z_score = (current_price - mean_price) / std_price
            return z_score

        return 0.0

class VolatilitySignalGenerator(SignalGenerator):
    """æ³¢åŠ¨ç‡å› å­ä¿¡å·ç”Ÿæˆå™¨ - ä½æ³¢åŠ¨ç‡åå‘ç­–ç•¥"""

    def __init__(self, lookback_period: int = 20, volatility_percentile: float = 0.3):
        super().__init__(f"LowVolatility_{lookback_period}days_{volatility_percentile}")
        self.lookback_period = lookback_period
        self.volatility_percentile = volatility_percentile

    def generate_signals(self, snapshot: DataSnapshot) -> List[TradingInstruction]:
        instructions = []

        for stock_code, factors in snapshot.factor_data.items():
            if 'volatility_rank' in factors and not pd.isna(factors['volatility_rank']):
                vol_rank = factors['volatility_rank']

                # ä¹°å…¥æ³¢åŠ¨ç‡æœ€ä½çš„è‚¡ç¥¨ï¼ˆä½æ³¢åŠ¨ç‡å¼‚å¸¸ï¼‰
                if vol_rank <= self.volatility_percentile:
                    instructions.append(TradingInstruction(
                        stock_code=stock_code,
                        action='BUY',
                        quantity=1000,
                        reason=f"Low Volatility: rank {vol_rank:.4f} <= {self.volatility_percentile}",
                        timestamp=snapshot.date
                    ))

        return instructions

    @staticmethod
    def calculate_volatility(data: pd.DataFrame, lookback_period: int = 20) -> float:
        """è®¡ç®—æ³¢åŠ¨ç‡å› å­ï¼šè¿‡å»Nå¤©æ”¶ç›Šç‡çš„æ ‡å‡†å·®"""
        if len(data) < lookback_period:
            return np.nan

        returns = data['close'].pct_change().iloc[-lookback_period:].dropna()
        if len(returns) > 0:
            return returns.std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡

        return np.nan

class LiquiditySignalGenerator(SignalGenerator):
    """æµåŠ¨æ€§å› å­ä¿¡å·ç”Ÿæˆå™¨ - åŸºäºæˆäº¤é‡çš„æµåŠ¨æ€§ç­–ç•¥"""

    def __init__(self, lookback_period: int = 20, liquidity_threshold: float = 0.5):
        super().__init__(f"Liquidity_{lookback_period}days_{liquidity_threshold}")
        self.lookback_period = lookback_period
        self.liquidity_threshold = liquidity_threshold

    def generate_signals(self, snapshot: DataSnapshot) -> List[TradingInstruction]:
        instructions = []

        for stock_code, factors in snapshot.factor_data.items():
            if 'liquidity_score' in factors and not pd.isna(factors['liquidity_score']):
                liquidity = factors['liquidity_score']

                # ä¹°å…¥æµåŠ¨æ€§é€‚ä¸­çš„è‚¡ç¥¨ï¼ˆé¿å…æµåŠ¨æ€§è¿‡é«˜æˆ–è¿‡ä½ï¼‰
                if self.liquidity_threshold <= liquidity <= 2.0:
                    instructions.append(TradingInstruction(
                        stock_code=stock_code,
                        action='BUY',
                        quantity=1000,
                        reason=f"Liquidity: {liquidity:.4f} in optimal range",
                        timestamp=snapshot.date
                    ))

        return instructions

    @staticmethod
    def calculate_liquidity(data: pd.DataFrame, lookback_period: int = 20) -> float:
        """è®¡ç®—æµåŠ¨æ€§å› å­ï¼šå¹³å‡æˆäº¤é¢/å¸‚å€¼çš„ä»£ç†æŒ‡æ ‡"""
        if len(data) < lookback_period:
            return np.nan

        recent_data = data.iloc[-lookback_period:]
        avg_turnover = (recent_data['volume'] * recent_data['close']).mean()
        avg_market_cap = recent_data['close'].mean() * 100000000  # å‡è®¾è‚¡æœ¬ä¸º1äº¿

        if avg_market_cap > 0:
            liquidity_ratio = avg_turnover / avg_market_cap
            return liquidity_ratio

        return np.nan

class CompositeSignalGenerator(SignalGenerator):
    """å¤åˆå› å­ä¿¡å·ç”Ÿæˆå™¨ - å¤šå› å­ç»„åˆç­–ç•¥"""

    def __init__(self, factors: List[str] = None, weights: List[float] = None):
        if factors is None:
            factors = ['momentum', 'mean_reversion', 'volatility', 'liquidity']
        if weights is None:
            weights = [0.25, 0.25, 0.25, 0.25]

        factor_str = '_'.join([f"{f}_{w}" for f, w in zip(factors, weights)])
        super().__init__(f"Composite_{factor_str}")
        self.factors = factors
        self.weights = weights

    def generate_signals(self, snapshot: DataSnapshot) -> List[TradingInstruction]:
        instructions = []

        for stock_code, factors in snapshot.factor_data.items():
            composite_score = 0.0
            valid_factors = 0

            for factor, weight in zip(self.factors, self.weights):
                factor_key = f"{factor}_score"
                if factor_key in factors and not pd.isna(factors[factor_key]):
                    composite_score += weight * factors[factor_key]
                    valid_factors += 1

            # åªè€ƒè™‘æœ‰è¶³å¤Ÿå› å­æ•°æ®çš„è‚¡ç¥¨
            if valid_factors >= len(self.factors) * 0.5 and composite_score > 0.3:
                instructions.append(TradingInstruction(
                    stock_code=stock_code,
                    action='BUY',
                    quantity=1000,
                    reason=f"Composite Score: {composite_score:.4f}",
                    timestamp=snapshot.date
                ))

        return instructions

class AdvancedFactorHunter:
    """é«˜çº§å› å­ç‹©çŒå™¨ - ç³»ç»Ÿæ€§æµ‹è¯•å¤šç§å› å­"""

    def __init__(self, data_dir: str = "data/historical/stocks/complete_csi800/stocks"):
        self.data_dir = Path(data_dir)
        self.results_dir = Path("advanced_factor_hunt_results")
        self.results_dir.mkdir(exist_ok=True)

    def enhance_data_snapshot_with_advanced_factors(self, snapshot: DataSnapshot) -> DataSnapshot:
        """ä¸ºæ•°æ®å¿«ç…§æ·»åŠ é«˜çº§å› å­æ•°æ®"""
        enhanced_factor_data = {}

        for stock_code, stock_data in snapshot.stock_data.items():
            enhanced_factor_data[stock_code] = {}

            # è·å–å†å²æ•°æ®ç”¨äºè®¡ç®—å› å­
            data = self._load_stock_historical_data(stock_code, snapshot.date)
            if data is None or len(data) < 30:
                continue

            # è®¡ç®—å„ç§å› å­
            factors = {
                'momentum_score': MomentumSignalGenerator.calculate_momentum(data, 20),
                'momentum_60d': MomentumSignalGenerator.calculate_momentum(data, 60),
                'mean_reversion_score': MeanReversionSignalGenerator.calculate_mean_reversion(data, 20),
                'volatility_score': VolatilitySignalGenerator.calculate_volatility(data, 20),
                'liquidity_score': LiquiditySignalGenerator.calculate_liquidity(data, 20),
            }

            # è®¡ç®—å¤åˆå› å­
            valid_scores = [v for k, v in factors.items() if not pd.isna(v)]
            if len(valid_scores) >= 3:
                # æ ‡å‡†åŒ–å¹¶è®¡ç®—å¤åˆå¾—åˆ†
                normalized_scores = [(s - min(valid_scores)) / (max(valid_scores) - min(valid_scores) + 1e-8) for s in valid_scores]
                factors['composite_score'] = np.mean(normalized_scores)

            enhanced_factor_data[stock_code].update(factors)

        # è®¡ç®—æ¨ªæˆªé¢æ’åºå› å­ï¼ˆå¦‚æ³¢åŠ¨ç‡æ’åï¼‰
        self._calculate_cross_sectional_ranks(enhanced_factor_data)

        return DataSnapshot(
            date=snapshot.date,
            stock_data=snapshot.stock_data,
            market_data=snapshot.market_data,
            factor_data=enhanced_factor_data,
            is_valid=snapshot.is_valid
        )

    def _calculate_cross_sectional_ranks(self, factor_data: Dict[str, Dict]):
        """è®¡ç®—æ¨ªæˆªé¢æ’åºå› å­"""
        # è®¡ç®—æ³¢åŠ¨ç‡æ’å
        volatilities = []
        for stock_code, factors in factor_data.items():
            if 'volatility_score' in factors and not pd.isna(factors['volatility_score']):
                volatilities.append((stock_code, factors['volatility_score']))

        if len(volatilities) > 10:
            volatilities.sort(key=lambda x: x[1])
            for rank, (stock_code, _) in enumerate(volatilities):
                factor_data[stock_code]['volatility_rank'] = rank / len(volatilities)

    def _load_stock_historical_data(self, stock_code: str, current_date: str) -> pd.DataFrame:
        """åŠ è½½ä¸ªè‚¡å†å²æ•°æ®"""
        try:
            # è·å–å¹´ä»½ - æ”¯æŒå­—ç¬¦ä¸²å’Œæ—¥æœŸæ ¼å¼
            if isinstance(current_date, str):
                year = current_date.split('-')[0]
                current_dt = pd.to_datetime(current_date)
            else:
                year = str(current_date.year)
                current_dt = current_date

            file_path = self.data_dir / year / f"{stock_code}.csv"

            if file_path.exists():
                data = pd.read_csv(file_path)
                data['date'] = pd.to_datetime(data['date'])

                # è·å–å½“å‰æ—¥æœŸä¹‹å‰çš„æ•°æ®
                historical_data = data[data['date'] <= current_dt].copy()

                return historical_data
        except Exception as e:
            logger.warning(f"åŠ è½½ {stock_code} å†å²æ•°æ®å¤±è´¥: {e}")

        return None

    def run_advanced_factor_tests(self, stock_codes: List[str], start_date: str, end_date: str) -> Dict[str, Any]:
        """è¿è¡Œé«˜çº§å› å­æµ‹è¯•"""
        logger.info(f"å¼€å§‹é«˜çº§å› å­æµ‹è¯•: {len(stock_codes)} åªè‚¡ç¥¨, {start_date} åˆ° {end_date}")

        # å®šä¹‰è¦æµ‹è¯•çš„å› å­ç”Ÿæˆå™¨
        factor_generators = [
            ("Momentum_20days_0.05", MomentumSignalGenerator(20, 0.05)),
            ("Momentum_60days_0.10", MomentumSignalGenerator(60, 0.10)),
            ("MeanReversion_20days_2std", MeanReversionSignalGenerator(20, 2.0)),
            ("LowVolatility_20days_0.3", VolatilitySignalGenerator(20, 0.3)),
            ("Liquidity_20days_0.5", LiquiditySignalGenerator(20, 0.5)),
        ]

        results = {}

        for factor_name, generator in factor_generators:
            logger.info(f"æµ‹è¯•å› å­: {factor_name}")

            try:
                result = self.run_single_factor_test(factor_name, generator, stock_codes, start_date, end_date)
                results[factor_name] = result

                # ä¿å­˜å•ä¸ªå› å­ç»“æœ
                self._save_factor_result(factor_name, result)

            except Exception as e:
                logger.error(f"å› å­ {factor_name} æµ‹è¯•å¤±è´¥: {e}")
                results[factor_name] = {"error": str(e)}

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(results)

        return results

    def run_single_factor_test(self, factor_name: str, generator: SignalGenerator,
                              stock_codes: List[str], start_date: str, end_date: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå› å­æµ‹è¯•"""

        class CustomBacktestEngine(BiasFreeBacktestEngine):
            def __init__(self, factor_hunter):
                super().__init__()
                self.factor_hunter = factor_hunter

            def create_data_snapshot(self, date, stock_data):
                basic_snapshot = super().create_data_snapshot(date, stock_data)
                enhanced_snapshot = self.factor_hunter.enhance_data_snapshot_with_advanced_factors(basic_snapshot)
                return enhanced_snapshot

        custom_engine = CustomBacktestEngine(self)
        custom_engine.add_signal_generator(generator)

        results = custom_engine.run_bias_free_backtest(stock_codes, start_date, end_date)

        return results

    def _serialize_result(self, obj):
        """é€’å½’åºåˆ—åŒ–ç»“æœå¯¹è±¡ï¼Œå¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡"""
        if isinstance(obj, dict):
            return {k: self._serialize_result(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._serialize_result(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            # å¤„ç†è‡ªå®šä¹‰å¯¹è±¡
            return str(obj)
        elif hasattr(obj, 'isoformat'):  # datetimeå¯¹è±¡
            return obj.isoformat()
        else:
            return obj

    def _save_factor_result(self, factor_name: str, result: Dict[str, Any]):
        """ä¿å­˜å•ä¸ªå› å­æµ‹è¯•ç»“æœ"""
        result_file = self.results_dir / f"{factor_name}_results.json"

        # åºåˆ—åŒ–ç»“æœ
        serializable_result = self._serialize_result(result)

        # æ·»åŠ å…ƒæ•°æ®
        result_with_meta = {
            "factor_name": factor_name,
            "test_time": datetime.now().isoformat(),
            "results": serializable_result
        }

        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_with_meta, f, indent=2, ensure_ascii=False)

        logger.info(f"å› å­ {factor_name} ç»“æœå·²ä¿å­˜åˆ° {result_file}")

    def _generate_comprehensive_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("# Advanced Factor Hunt Report - é«˜çº§å› å­æœç´¢æŠ¥å‘Š")
        report_lines.append("=" * 80)
        report_lines.append(f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"**æµ‹è¯•å› å­æ•°é‡**: {len(results)}")
        report_lines.append("")

        # ç»Ÿè®¡ç»“æœ
        successful_tests = 0
        failed_tests = 0
        factor_performance = []

        for factor_name, result in results.items():
            if "error" in result:
                failed_tests += 1
                report_lines.append(f"### âŒ {factor_name}")
                report_lines.append(f"**é”™è¯¯**: {result['error']}")
                report_lines.append("")
            else:
                successful_tests += 1
                performance = result.get('total_return', 0)
                sharpe = result.get('sharpe_ratio', 0)
                max_drawdown = result.get('max_drawdown', 0)

                factor_performance.append({
                    'name': factor_name,
                    'return': performance,
                    'sharpe': sharpe,
                    'max_dd': max_drawdown
                })

                # æœ‰æ•ˆæ€§è¯„åˆ†
                effectiveness_score = 0
                if performance > 5:
                    effectiveness_score += 30
                elif performance > 0:
                    effectiveness_score += 15

                if sharpe > 1:
                    effectiveness_score += 40
                elif sharpe > 0.5:
                    effectiveness_score += 20
                elif sharpe > 0:
                    effectiveness_score += 10

                if max_drawdown < 10:
                    effectiveness_score += 30
                elif max_drawdown < 20:
                    effectiveness_score += 15

                recommendation = "ACCEPT" if effectiveness_score >= 60 else "REJECT"

                report_lines.append(f"### {'âœ…' if effectiveness_score >= 60 else 'ğŸŸ¡'} {factor_name}")
                report_lines.append(f"**å¹´åŒ–æ”¶ç›Š**: {performance:.2f}%")
                report_lines.append(f"**å¤æ™®æ¯”ç‡**: {sharpe:.2f}")
                report_lines.append(f"**æœ€å¤§å›æ’¤**: {max_drawdown:.2f}%")
                report_lines.append(f"**æœ‰æ•ˆæ€§è¯„åˆ†**: {effectiveness_score}/100")
                report_lines.append(f"**å»ºè®®**: {recommendation}")
                report_lines.append("")

        # æ€§èƒ½æ’å
        if factor_performance:
            factor_performance.sort(key=lambda x: x['return'], reverse=True)
            report_lines.append("## ğŸ“Š å› å­æ€§èƒ½æ’å")
            report_lines.append("")
            report_lines.append("| æ’å | å› å­åç§° | å¹´åŒ–æ”¶ç›Š | å¤æ™®æ¯”ç‡ | æœ€å¤§å›æ’¤ |")
            report_lines.append("|------|----------|----------|----------|----------|")

            for i, factor in enumerate(factor_performance, 1):
                report_lines.append(f"| {i} | {factor['name']} | {factor['return']:.2f}% | {factor['sharpe']:.2f} | {factor['max_dd']:.2f}% |")
            report_lines.append("")

        # æ€»ç»“
        report_lines.append("## ğŸ¯ æµ‹è¯•æ€»ç»“")
        report_lines.append(f"**æˆåŠŸæµ‹è¯•**: {successful_tests}")
        report_lines.append(f"**å¤±è´¥æµ‹è¯•**: {failed_tests}")
        report_lines.append("")

        if factor_performance:
            best_factor = factor_performance[0]
            report_lines.append(f"**æœ€ä½³å› å­**: {best_factor['name']} (å¹´åŒ–æ”¶ç›Š: {best_factor['return']:.2f}%)")

            # æ‰¾å‡ºæ­£æ”¶ç›Šçš„å› å­
            positive_factors = [f for f in factor_performance if f['return'] > 0]
            if positive_factors:
                report_lines.append(f"**æ­£æ”¶ç›Šå› å­æ•°é‡**: {len(positive_factors)}/{len(factor_performance)}")
            else:
                report_lines.append("**âš ï¸ å…³é”®å‘ç°**: æ‰€æœ‰å› å­éƒ½æœªèƒ½äº§ç”Ÿæ­£æ”¶ç›Šï¼Œéœ€è¦é‡æ–°å®¡è§†ç­–ç•¥")

        report_lines.append("")
        report_lines.append("---")
        report_lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("*åŸºäºæ— åå·®å›æµ‹å¼•æ“çš„ä¸¥æ ¼æµ‹è¯•*")

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.results_dir / "advanced_factor_hunt_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        logger.info(f"ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºé«˜çº§å› å­ç‹©çŒå™¨
    hunter = AdvancedFactorHunter()

    # å®šä¹‰æµ‹è¯•å‚æ•°
    stock_codes = ['000001', '000002', '600036', '600519', '000858']  # æµ‹è¯•è‚¡ç¥¨ç»„åˆ
    start_date = '2022-01-01'
    end_date = '2023-12-31'

    logger.info("å¼€å§‹é«˜çº§å› å­æœç´¢æµ‹è¯•...")

    # è¿è¡Œæµ‹è¯•
    results = hunter.run_advanced_factor_tests(stock_codes, start_date, end_date)

    logger.info("é«˜çº§å› å­æœç´¢æµ‹è¯•å®Œæˆï¼")
    logger.info(f"ç»“æœä¿å­˜åœ¨: {hunter.results_dir}")

if __name__ == "__main__":
    main()