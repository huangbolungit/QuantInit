#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–æ•°æ®è´¨é‡éªŒè¯è„šæœ¬
éªŒè¯æ²ªæ·±300è‚¡ç¥¨æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import logging
import json

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SimpleDataValidator:
    """ç®€åŒ–çš„æ•°æ®è´¨é‡éªŒè¯å™¨"""

    def __init__(self, data_dir: str = None):
        self.data_dir = Path(data_dir) if data_dir else Path("data/historical/stocks/csi300_5year")
        self.stocks_dir = self.data_dir / "stocks"
        self.reports_dir = self.data_dir / "reports"

        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        self.reports_dir.mkdir(exist_ok=True)

        logger.info(f"æ•°æ®è´¨é‡éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®ç›®å½•: {self.data_dir}")

    def load_stock_data(self, stock_code: str) -> pd.DataFrame:
        """åŠ è½½å•åªè‚¡ç¥¨çš„æ‰€æœ‰å¹´ä»½æ•°æ®"""
        all_data = []

        # éå†æ‰€æœ‰å¹´ä»½ç›®å½•
        for year_dir in sorted(self.stocks_dir.iterdir()):
            if year_dir.is_dir() and year_dir.name.isdigit():
                file_path = year_dir / f"{stock_code}.csv"
                if file_path.exists():
                    try:
                        df = pd.read_csv(file_path)
                        df['date'] = pd.to_datetime(df['date'])
                        all_data.append(df)
                    except Exception as e:
                        logger.warning(f"è¯»å– {file_path} å¤±è´¥: {e}")

        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            combined_df = combined_df.sort_values('date').drop_duplicates(subset=['date'], keep='last')
            return combined_df
        else:
            return pd.DataFrame()

    def validate_single_stock(self, stock_code: str) -> Dict[str, Any]:
        """éªŒè¯å•åªè‚¡ç¥¨çš„æ•°æ®è´¨é‡"""
        try:
            df = self.load_stock_data(stock_code)

            if df.empty:
                return {
                    'stock_code': stock_code,
                    'status': 'no_data',
                    'total_records': 0,
                    'date_range': None,
                    'quality_score': 0.0
                }

            # åŸºæœ¬ç»Ÿè®¡
            total_records = len(df)
            date_range = {
                'start': df['date'].min().strftime('%Y-%m-%d'),
                'end': df['date'].max().strftime('%Y-%m-%d'),
                'trading_days': total_records
            }

            # ç¼ºå¤±å€¼æ£€æŸ¥
            missing_values = df.isnull().sum().sum()

            # ä»·æ ¼æ•°æ®åˆç†æ€§æ£€æŸ¥
            price_issues = 0
            for col in ['open', 'high', 'low', 'close']:
                if col in df.columns:
                    price_issues += (df[col] <= 0).sum()
                    price_issues += (df[col] > 10000).sum()

            # è®¡ç®—è´¨é‡åˆ†æ•°
            quality_score = 1.0
            quality_score -= (price_issues / total_records) * 0.3
            quality_score -= (missing_values / (total_records * len(df.columns))) * 0.2
            quality_score = max(0, min(1, quality_score))

            # è®¡ç®—æ”¶ç›Šç‡ç»Ÿè®¡
            return_stats = {}
            if 'close' in df.columns and len(df) > 1:
                df['daily_return'] = df['close'].pct_change()
                return_stats = {
                    'mean_daily_return': round(df['daily_return'].mean(), 6),
                    'std_daily_return': round(df['daily_return'].std(), 6),
                    'max_return': round(df['daily_return'].max(), 6),
                    'min_return': round(df['daily_return'].min(), 6)
                }

            return {
                'stock_code': stock_code,
                'status': 'valid',
                'total_records': total_records,
                'date_range': date_range,
                'missing_values': missing_values,
                'price_issues': price_issues,
                'quality_score': round(quality_score, 3),
                'return_statistics': return_stats
            }

        except Exception as e:
            logger.error(f"éªŒè¯ {stock_code} æ—¶å‡ºé”™: {e}")
            return {
                'stock_code': stock_code,
                'status': 'error',
                'error': str(e),
                'quality_score': 0.0
            }

    def validate_all_stocks(self) -> Dict[str, Any]:
        """éªŒè¯æ‰€æœ‰è‚¡ç¥¨æ•°æ®è´¨é‡"""
        logger.info("å¼€å§‹éªŒè¯æ‰€æœ‰è‚¡ç¥¨æ•°æ®è´¨é‡...")

        # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
        stock_files = list(self.stocks_dir.rglob("*.csv"))
        stock_codes = set()
        for file_path in stock_files:
            stock_code = file_path.stem
            if stock_code.isdigit() and len(stock_code) == 6:
                stock_codes.add(stock_code)

        stock_codes = sorted(list(stock_codes))
        logger.info(f"å‘ç° {len(stock_codes)} åªè‚¡ç¥¨çš„æ•°æ®")

        validation_results = {}
        quality_scores = []
        total_records = []

        for i, stock_code in enumerate(stock_codes, 1):
            if i % 10 == 0:
                logger.info(f"éªŒè¯è¿›åº¦: {i}/{len(stock_codes)}")

            result = self.validate_single_stock(stock_code)
            validation_results[stock_code] = result

            if result['status'] == 'valid':
                quality_scores.append(result['quality_score'])
                total_records.append(result['total_records'])

        # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
        if quality_scores:
            summary_stats = {
                'total_stocks': len(stock_codes),
                'valid_stocks': len([r for r in validation_results.values() if r['status'] == 'valid']),
                'invalid_stocks': len([r for r in validation_results.values() if r['status'] != 'valid']),
                'avg_quality_score': round(np.mean(quality_scores), 3),
                'min_quality_score': round(np.min(quality_scores), 3),
                'max_quality_score': round(np.max(quality_scores), 3),
                'avg_records_per_stock': round(np.mean(total_records), 0),
                'total_records_all_stocks': int(np.sum(total_records)),
                'quality_distribution': {
                    'excellent (>0.9)': len([s for s in quality_scores if s > 0.9]),
                    'good (0.7-0.9)': len([s for s in quality_scores if 0.7 <= s <= 0.9]),
                    'fair (0.5-0.7)': len([s for s in quality_scores if 0.5 <= s < 0.7]),
                    'poor (<0.5)': len([s for s in quality_scores if s < 0.5])
                }
            }
        else:
            summary_stats = {
                'total_stocks': len(stock_codes),
                'valid_stocks': 0,
                'invalid_stocks': len(stock_codes),
                'avg_quality_score': 0,
                'message': 'No valid data found'
            }

        report = {
            'summary': summary_stats,
            'individual_stocks': validation_results,
            'validation_timestamp': datetime.now().isoformat()
        }

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.reports_dir / f"data_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"æ•°æ®è´¨é‡éªŒè¯å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        logger.info(f"æ€»è®¡: {summary_stats['total_stocks']} åªè‚¡ç¥¨")
        logger.info(f"æœ‰æ•ˆ: {summary_stats['valid_stocks']} åª")
        logger.info(f"å¹³å‡è´¨é‡åˆ†æ•°: {summary_stats['avg_quality_score']}")

        return report


def main():
    print("æ²ªæ·±300è‚¡ç¥¨æ•°æ®è´¨é‡éªŒè¯")
    print("=" * 50)

    try:
        # åˆ›å»ºéªŒè¯å™¨
        validator = SimpleDataValidator()

        # è¿è¡ŒéªŒè¯
        report = validator.validate_all_stocks()

        # æ‰“å°ç®€è¦ç»“æœ
        summary = report['summary']
        print(f"\nğŸ“Š æ•°æ®è´¨é‡éªŒè¯ç»“æœ:")
        print(f"æ€»è‚¡ç¥¨æ•°: {summary['total_stocks']}")
        print(f"æœ‰æ•ˆè‚¡ç¥¨: {summary['valid_stocks']}")
        print(f"æ— æ•ˆè‚¡ç¥¨: {summary['invalid_stocks']}")
        print(f"å¹³å‡è´¨é‡åˆ†æ•°: {summary['avg_quality_score']}")
        print(f"å¹³å‡æ¯åªè‚¡ç¥¨è®°å½•æ•°: {summary['avg_records_per_stock']:.0f}")

        if 'quality_distribution' in summary:
            print(f"\nğŸ“ˆ è´¨é‡åˆ†å¸ƒ:")
            for level, count in summary['quality_distribution'].items():
                print(f"  {level}: {count} åª")

        # æ˜¾ç¤ºä¸€äº›ä¼˜è´¨è‚¡ç¥¨ç¤ºä¾‹
        valid_stocks = {k: v for k, v in report['individual_stocks'].items() if v['status'] == 'valid'}
        if valid_stocks:
            # æŒ‰è´¨é‡åˆ†æ•°æ’åº
            sorted_stocks = sorted(valid_stocks.items(), key=lambda x: x[1]['quality_score'], reverse=True)
            print(f"\nğŸ† è´¨é‡æœ€é«˜çš„5åªè‚¡ç¥¨:")
            for i, (stock_code, data) in enumerate(sorted_stocks[:5], 1):
                print(f"  {i}. {stock_code}: è´¨é‡åˆ†æ•° {data['quality_score']}, è®°å½•æ•° {data['total_records']}, "
                      f"æ—¶é—´èŒƒå›´ {data['date_range']['start']} åˆ° {data['date_range']['end']}")

    except Exception as e:
        logger.error(f"æ•°æ®è´¨é‡éªŒè¯å¤±è´¥: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())