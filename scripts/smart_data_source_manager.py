#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ•°æ®æºç®¡ç†å™¨ - è§£å†³å¤šæ•°æ®æºé™é€Ÿé—®é¢˜çš„ç»Ÿä¸€è§£å†³æ–¹æ¡ˆ
"""

import os
import sys
import time
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import pandas as pd

# Add project root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from backend.app.services.data_acquisition.akshare_client import AkShareDataAcquirer
from backend.app.services.data_acquisition.tushare_client import TushareDataAcquirer
from backend.app.services.data_acquisition.yahoo_finance_client_enhanced import EnhancedYahooFinanceClient
from backend.app.services.data_acquisition.baostock_client import BaoStockClient

logger = logging.getLogger(__name__)


class SmartDataSourceManager:
    """æ™ºèƒ½æ•°æ®æºç®¡ç†å™¨ - è‡ªåŠ¨åˆ‡æ¢å’Œä¼˜åŒ–æ•°æ®è·å–"""

    def __init__(self):
        self.data_sources = {}

        # å°è¯•åˆå§‹åŒ–å„ä¸ªæ•°æ®æºï¼ŒBaoStockä¼˜å…ˆ
        try:
            self.data_sources['baostock'] = BaoStockClient()
            logger.info("âœ… BaoStock client initialized")
        except Exception as e:
            logger.warning(f"âŒ Failed to initialize BaoStock client: {e}")

        try:
            self.data_sources['yahoo'] = EnhancedYahooFinanceClient()
            logger.info("âœ… Yahoo Finance client initialized")
        except Exception as e:
            logger.warning(f"âŒ Failed to initialize Yahoo Finance client: {e}")

        try:
            self.data_sources['akshare'] = AkShareDataAcquirer()
            logger.info("âœ… AkShare client initialized")
        except Exception as e:
            logger.warning(f"âŒ Failed to initialize AkShare client: {e}")

        try:
            self.data_sources['tushare'] = TushareDataAcquirer()
            logger.info("âœ… Tushare client initialized")
        except Exception as e:
            logger.warning(f"âŒ Failed to initialize Tushare client: {e}")

        # ç§»é™¤ä¸å¯ç”¨çš„æ•°æ®æº
        unavailable_sources = [k for k, v in self.data_sources.items() if v is None]
        for source in unavailable_sources:
            del self.data_sources[source]
            logger.warning(f"âš ï¸ {source} client unavailable, removed from active sources")

        logger.info(f"Active data sources: {list(self.data_sources.keys())}")

        # æ•°æ®æºä¼˜å…ˆçº§ï¼ˆBaoStockä¼˜å…ˆï¼Œå› ä¸ºå…¶ç¨³å®šæ€§å’ŒCSI300ä¸“ç”¨æ”¯æŒï¼‰
        priority_order = ['baostock', 'yahoo', 'akshare', 'tushare']
        self.source_priority = [source for source in priority_order if source in self.data_sources.keys()]

        # æ•°æ®æºå¥åº·çŠ¶æ€ï¼ˆåªåŒ…å«å¯ç”¨çš„æ•°æ®æºï¼‰
        self.source_health = {
            source: {'status': 'unknown', 'last_check': None, 'consecutive_failures': 0}
            for source in self.data_sources.keys()
        }

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'successful_downloads': 0,
            'failed_downloads': 0,
            'source_usage': {source: 0 for source in self.data_sources.keys()}
        }

    def check_source_health(self, source_name: str) -> bool:
        """æ£€æŸ¥æ•°æ®æºå¥åº·çŠ¶æ€"""
        client = self.data_sources[source_name]

        try:
            logger.info(f"Checking health of {source_name}...")

            if source_name == 'baostock':
                # BaoStockæµ‹è¯• - å°è¯•ç™»å½•å’Œè·å–å°‘é‡æ•°æ®
                if client.login():
                    test_data = client.download_stock_data("sh.600000", "2024-12-01", "2024-12-05")
                    health = test_data is not None and len(test_data) > 0
                    client.logout()
                else:
                    health = False
            elif source_name == 'yahoo':
                # Yahoo Financeæµ‹è¯•
                health = client.test_connectivity()
            elif source_name == 'akshare':
                # AkShareæµ‹è¯• - å°è¯•è·å–å°‘é‡æ•°æ®
                test_symbol = "000001.SS"
                test_data = client.get_stock_daily_data(test_symbol, "2024-12-01", "2024-12-31")
                health = test_data is not None and len(test_data) > 0
            elif source_name == 'tushare':
                # Tushareæµ‹è¯•
                test_symbol = "000001.SS"
                test_data = client.get_stock_daily_data(test_symbol, "2024-12-01", "2024-12-31")
                health = test_data is not None and len(test_data) > 0
            else:
                health = False

            # æ›´æ–°å¥åº·çŠ¶æ€
            self.source_health[source_name]['status'] = 'healthy' if health else 'unhealthy'
            self.source_health[source_name]['last_check'] = datetime.now()

            if health:
                self.source_health[source_name]['consecutive_failures'] = 0
                logger.info(f"âœ… {source_name} is healthy")
            else:
                self.source_health[source_name]['consecutive_failures'] += 1
                logger.warning(f"âŒ {source_name} is unhealthy (failures: {self.source_health[source_name]['consecutive_failures']})")

            return health

        except Exception as e:
            logger.error(f"Health check failed for {source_name}: {e}")
            self.source_health[source_name]['status'] = 'error'
            self.source_health[source_name]['last_check'] = datetime.now()
            self.source_health[source_name]['consecutive_failures'] += 1
            return False

    def get_best_available_source(self) -> Optional[str]:
        """è·å–å½“å‰å¯ç”¨çš„æœ€ä½³æ•°æ®æº"""
        available_sources = []

        for source_name in self.source_priority:
            # è·³è¿‡å·²ç»å¤±è´¥å¤šæ¬¡çš„æ•°æ®æº
            if self.source_health[source_name]['consecutive_failures'] >= 3:
                logger.warning(f"Skipping {source_name} (too many failures)")
                continue

            # æ£€æŸ¥æ•°æ®æºå¥åº·çŠ¶æ€
            if self.source_health[source_name]['status'] == 'healthy':
                # å¦‚æœä¸Šæ¬¡æ£€æŸ¥è¶…è¿‡5åˆ†é’Ÿï¼Œé‡æ–°æ£€æŸ¥
                if (self.source_health[source_name]['last_check'] is None or
                    datetime.now() - self.source_health[source_name]['last_check'] > timedelta(minutes=5)):
                    if self.check_source_health(source_name):
                        available_sources.append(source_name)
                else:
                    available_sources.append(source_name)
            else:
                # å°è¯•æ£€æŸ¥æ•°æ®æº
                if self.check_source_health(source_name):
                    available_sources.append(source_name)

        if available_sources:
            best_source = available_sources[0]
            logger.info(f"Selected best available source: {best_source}")
            return best_source
        else:
            logger.warning("No healthy data sources available")
            return None

    def download_stock_with_fallback(self, symbol: str, start_date: str, end_date: str,
                                   max_attempts: int = 3) -> Optional[pd.DataFrame]:
        """å¸¦å›é€€æœºåˆ¶çš„è‚¡ç¥¨æ•°æ®ä¸‹è½½"""
        self.stats['total_requests'] += 1

        for attempt in range(max_attempts):
            best_source = self.get_best_available_source()

            if best_source is None:
                logger.error("No available data sources")
                self.stats['failed_downloads'] += 1
                return None

            logger.info(f"Attempting to download {symbol} using {best_source} (attempt {attempt + 1})")
            self.stats['source_usage'][best_source] += 1

            try:
                client = self.data_sources[best_source]

                if best_source == 'baostock':
                    # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼: 000001.SS -> sh.000001 æˆ– sz.000001
                    baostock_symbol = self._convert_to_baostock_format(symbol)
                    if baostock_symbol and client.login():
                        data = client.download_stock_data(baostock_symbol, start_date, end_date)
                        client.logout()
                    else:
                        data = None
                elif best_source == 'yahoo':
                    data = client.download_single_stock(symbol, start_date, end_date)
                else:
                    data = client.get_stock_daily_data(symbol, start_date, end_date)

                if data is not None and len(data) > 0:
                    self.stats['successful_downloads'] += 1
                    logger.info(f"âœ… Successfully downloaded {symbol} using {best_source}")
                    return data
                else:
                    logger.warning(f"No data returned from {best_source} for {symbol}")
                    # æ ‡è®°æ•°æ®æºä¸ºä¸å¥åº·
                    self.source_health[best_source]['status'] = 'unhealthy'
                    continue

            except Exception as e:
                logger.error(f"Error downloading {symbol} from {best_source}: {e}")
                # æ ‡è®°æ•°æ®æºä¸ºä¸å¥åº·
                self.source_health[best_source]['status'] = 'error'
                continue

        logger.error(f"Failed to download {symbol} after {max_attempts} attempts")
        self.stats['failed_downloads'] += 1
        return None

    def download_multiple_stocks_smart(self, symbols: List[str], start_date: str, end_date: str,
                                        max_concurrent: int = 3) -> Dict[str, pd.DataFrame]:
        """æ™ºèƒ½å¤šè‚¡ç¥¨ä¸‹è½½"""
        results = {}
        failed_symbols = []

        logger.info(f"Starting smart download of {len(symbols)} symbols")
        logger.info(f"Max concurrent downloads: {max_concurrent}")

        # åˆ†æ‰¹å¤„ç†ä»¥é¿å…è¿‡è½½
        batch_size = max_concurrent
        total_batches = (len(symbols) + batch_size - 1) // batch_size

        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min((batch_num + 1) * batch_size, len(symbols))
            batch_symbols = symbols[start_idx:end_idx]

            logger.info(f"Processing batch {batch_num + 1}/{total_batches}: {batch_symbols}")

            # å¯¹äºYahoo Financeï¼Œä½¿ç”¨æ‰¹é‡ä¸‹è½½
            yahoo_client = self.data_sources['yahoo']
            if (self.source_health['yahoo']['status'] == 'healthy' and
                len(batch_symbols) <= 5):  # Yahoo Financeæ‰¹é‡é™åˆ¶
                try:
                    logger.info(f"Using Yahoo Finance batch download for {len(batch_symbols)} symbols")
                    batch_results = yahoo_client.download_multiple_stocks_batch(
                        batch_symbols, start_date, end_date
                    )
                    results.update(batch_results)

                    # æ ‡è®°æˆåŠŸçš„è‚¡ç¥¨
                    for symbol in batch_symbols:
                        if symbol in batch_results:
                            self.stats['successful_downloads'] += 1
                            self.stats['source_usage']['yahoo'] += 1
                        else:
                            failed_symbols.append(symbol)

                    continue

                except Exception as e:
                    logger.warning(f"Yahoo Finance batch download failed: {e}")
                    # å›é€€åˆ°å•ä¸ªä¸‹è½½

            # å•ä¸ªä¸‹è½½ï¼ˆå›é€€æ–¹æ¡ˆï¼‰
            for symbol in batch_symbols:
                if symbol not in results:  # å¦‚æœæ‰¹é‡ä¸‹è½½æ²¡æœ‰æˆåŠŸ
                    data = self.download_stock_with_fallback(symbol, start_date, end_date)
                    if data is not None:
                        results[symbol] = data
                    else:
                        failed_symbols.append(symbol)

            # æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if batch_num < total_batches - 1:
                delay = 5.0  # æ‰¹æ¬¡é—´å»¶è¿Ÿ5ç§’
                logger.info(f"Waiting {delay}s before next batch...")
                time.sleep(delay)

        # æœ€ç»ˆç»Ÿè®¡
        success_count = len(results)
        total_count = len(symbols)
        success_rate = success_count / total_count * 100 if total_count > 0 else 0

        logger.info(f"Smart download completed:")
        logger.info(f"  Total symbols: {total_count}")
        logger.info(f"  Successful: {success_count}")
        logger.info(f"  Failed: {len(failed_symbols)}")
        logger.info(f"  Success rate: {success_rate:.1f}%")

        # è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"Source usage: {self.stats['source_usage']}")
        logger.info(f"Overall stats: {self.stats}")

        return results

    def get_comprehensive_report(self) -> Dict[str, Any]:
        """è·å–ç»¼åˆæŠ¥å‘Š"""
        return {
            'source_health': self.source_health,
            'statistics': self.stats,
            'recommendations': self._generate_recommendations()
        }

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åˆ†æå„æ•°æ®æºçŠ¶æ€
        for source_name, health in self.source_health.items():
            if health['consecutive_failures'] >= 3:
                recommendations.append(
                    f"è€ƒè™‘æ›´æ¢æˆ–å‡çº§ {source_name.upper()} æ•°æ®æº"
                )
            elif health['status'] == 'unhealthy':
                recommendations.append(
                    f"{source_name.upper()} æš‚æ—¶ä¸å¯ç”¨ï¼Œå»ºè®®ç­‰å¾…æˆ–ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ"
                )

        # åˆ†ææˆåŠŸç‡
        if self.stats['total_requests'] > 0:
            success_rate = self.stats['successful_downloads'] / self.stats['total_requests']
            if success_rate < 0.5:
                recommendations.append(
                    f"æ•´ä½“æˆåŠŸç‡è¾ƒä½ ({success_rate:.1%})ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ•°æ®æºé…ç½®"
                )
        else:
            recommendations.append("æš‚æ— ä¸‹è½½æ•°æ®ï¼Œå»ºè®®æµ‹è¯•æ•°æ®æºè¿æ¥")

        # åˆ†ææ•°æ®æºä½¿ç”¨æƒ…å†µ
        if self.stats['total_requests'] > 0:
            # æ‰¾åˆ°ä½¿ç”¨æœ€å¤šçš„æ•°æ®æºï¼Œç¡®ä¿è‡³å°‘æœ‰ä¸€æ¬¡ä½¿ç”¨
            source_usage_items = [(source, count) for source, count in self.stats['source_usage'].items() if count > 0]
            if source_usage_items:
                primary_source = max(source_usage_items, key=lambda x: x[1])[0]
                if self.stats['source_usage'][primary_source] / self.stats['total_requests'] > 0.8:
                    recommendations.append(
                        f"è¿‡åº¦ä¾èµ– {primary_source.upper()}ï¼Œå»ºè®®å¢åŠ æ•°æ®æºå¤šæ ·æ€§"
                    )

        if not recommendations:
            recommendations.append("æ‰€æœ‰æ•°æ®æºå·¥ä½œæ­£å¸¸ï¼Œå½“å‰é…ç½®è‰¯å¥½")

        return recommendations

    def _convert_to_baostock_format(self, symbol: str) -> Optional[str]:
        """
        å°†è‚¡ç¥¨ä»£ç è½¬æ¢ä¸ºBaoStockæ ¼å¼

        Args:
            symbol: åŸå§‹æ ¼å¼ï¼Œå¦‚ "000001.SS" æˆ– "600000.SS"

        Returns:
            str: BaoStockæ ¼å¼ï¼Œå¦‚ "sz.000001" æˆ– "sh.600000"
        """
        try:
            if '.' not in symbol:
                return None

            code, exchange = symbol.split('.')

            # è½¬æ¢äº¤æ˜“æ‰€ä»£ç 
            if exchange == 'SS':  # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
                return f"sh.{code}"
            elif exchange == 'SZ':  # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€
                return f"sz.{code}"
            else:
                logger.warning(f"Unknown exchange: {exchange}")
                return None

        except Exception as e:
            logger.error(f"Error converting symbol {symbol}: {e}")
            return None

    def download_csi300_with_baostock(self, start_date: str = '2020-01-01', end_date: str = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨BaoStockä¸“é—¨ä¸‹è½½CSI300æ•°æ®

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            Dict: ä¸‹è½½ç»“æœ
        """
        if 'baostock' not in self.data_sources:
            logger.error("BaoStock client not available")
            return {'success': False, 'error': 'BaoStock client not available'}

        client = self.data_sources['baostock']

        try:
            logger.info("ğŸ¯ Using BaoStock for CSI300 download...")
            results = client.download_csi300_complete(start_date, end_date, save_to_file=True)

            if results['success']:
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.stats['successful_downloads'] += results['successful']
                self.stats['failed_downloads'] += results['failed']
                self.stats['source_usage']['baostock'] += results['successful']

                logger.info(f"âœ… BaoStock CSI300 download completed: {results['successful']}/{results['total_stocks']} successful")

            return results

        except Exception as e:
            logger.error(f"âŒ BaoStock CSI300 download failed: {e}")
            return {'success': False, 'error': str(e)}


def main():
    """æµ‹è¯•å‡½æ•°"""
    manager = SmartDataSourceManager()

    # æ£€æŸ¥æ‰€æœ‰æ•°æ®æºå¥åº·çŠ¶æ€
    logger.info("=== Checking Data Source Health ===")
    for source in manager.data_sources.keys():
        manager.check_source_health(source)

    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    report = manager.get_comprehensive_report()
    logger.info("=== Comprehensive Report ===")
    logger.info(f"Source Health: {report['source_health']}")
    logger.info(f"Statistics: {report['statistics']}")
    logger.info(f"Recommendations: {report['recommendations']}")

    # æµ‹è¯•æ™ºèƒ½ä¸‹è½½
    test_symbols = ["000001.SS", "600519.SS"]
    start_date = "2024-12-01"
    end_date = "2024-12-31"

    logger.info(f"\n=== Testing Smart Download ===")
    results = manager.download_multiple_stocks_smart(test_symbols, start_date, end_date)

    for symbol, data in results.items():
        if data is not None:
            logger.info(f"{symbol}: {len(data)} records")
        else:
            logger.warning(f"{symbol}: Failed to download")

    # å¦‚æœBaoStockå¯ç”¨ï¼Œæµ‹è¯•CSI300ä¸‹è½½
    if 'baostock' in manager.data_sources:
        logger.info(f"\n=== Testing BaoStock CSI300 Download ===")
        csi300_results = manager.download_csi300_with_baostock(start_date, end_date)
        logger.info(f"CSI300 Download: {csi300_results.get('success', False)}")
        if csi300_results.get('success'):
            logger.info(f"  Downloaded: {csi300_results['successful']}/{csi300_results['total_stocks']} stocks")
            logger.info(f"  Total records: {csi300_results['total_records']:,}")
        else:
            logger.error(f"  Error: {csi300_results.get('error', 'Unknown error')}")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    main()