#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºç°æœ‰57åªè‚¡ç¥¨æ•°æ®çš„ç­–ç•¥éªŒè¯å·¥å…·
å……åˆ†åˆ©ç”¨å·²ä¸‹è½½çš„æ•°æ®è¿›è¡Œé‡åŒ–ç­–ç•¥ç ”ç©¶
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
import json
from datetime import datetime, timedelta

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('strategy_validation.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent / "backend"))

from app.services.backtesting.engine import BacktestEngine


class StrategyValidator:
    """åŸºäºç°æœ‰æ•°æ®çš„ç­–ç•¥éªŒè¯å™¨"""

    def __init__(self):
        self.data_dir = Path("data/historical/stocks/csi300_5year/stocks")
        self.results_dir = Path("data/validation_results")
        self.results_dir.mkdir(parents=True, exist_ok=True)

    def load_available_stocks(self) -> Dict[str, pd.DataFrame]:
        """åŠ è½½æ‰€æœ‰å¯ç”¨çš„è‚¡ç¥¨æ•°æ®"""
        available_stocks = {}

        logger.info("ğŸ” æ‰«æå¯ç”¨è‚¡ç¥¨æ•°æ®...")

        # éå†æ‰€æœ‰å¹´ä»½ç›®å½•
        for year_dir in self.data_dir.iterdir():
            if year_dir.is_dir() and year_dir.name.isdigit():
                year = int(year_dir.name)
                logger.info(f"ğŸ“… å¤„ç† {year} å¹´æ•°æ®...")

                # åŠ è½½è¯¥å¹´ä»½çš„æ‰€æœ‰è‚¡ç¥¨
                stock_files = list(year_dir.glob("*.csv"))
                logger.info(f"   æ‰¾åˆ° {len(stock_files)} ä¸ªè‚¡ç¥¨æ–‡ä»¶")

                for stock_file in stock_files:
                    stock_code = stock_file.stem
                    try:
                        df = pd.read_csv(stock_file)
                        df['date'] = pd.to_datetime(df['date'])

                        if stock_code not in available_stocks:
                            available_stocks[stock_code] = []
                        available_stocks[stock_code].append(df)

                    except Exception as e:
                        logger.warning(f"âŒ è¯»å– {stock_code} æ•°æ®å¤±è´¥: {e}")

        # åˆå¹¶æ¯åªè‚¡ç¥¨çš„æ‰€æœ‰å¹´ä»½æ•°æ®
        consolidated_stocks = {}
        for stock_code, dataframes in available_stocks.items():
            if dataframes:
                combined_df = pd.concat(dataframes, ignore_index=True)
                combined_df = combined_df.sort_values('date').drop_duplicates(subset=['date'])
                consolidated_stocks[stock_code] = combined_df

                logger.info(f"âœ… è‚¡ç¥¨ {stock_code}: {len(combined_df)} æ¡æ•°æ® ({combined_df['date'].min().date()} åˆ° {combined_df['date'].max().date()})")

        logger.info(f"ğŸ“Š æ€»å…±åŠ è½½äº† {len(consolidated_stocks)} åªè‚¡ç¥¨æ•°æ®")
        return consolidated_stocks

    def analyze_data_quality(self, stock_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """åˆ†ææ•°æ®è´¨é‡"""
        quality_info = {
            'total_stocks': len(stock_data),
            'date_ranges': {},
            'data_quality': {},
            'summary': {}
        }

        all_dates = set()
        total_records = 0

        for stock_code, df in stock_data.items():
            date_range = {
                'start': df['date'].min().date(),
                'end': df['date'].max().date(),
                'trading_days': len(df),
                'total_records': len(df)
            }
            quality_info['date_ranges'][stock_code] = date_range

            # æ”¶é›†æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
            dates = set(df['date'].dt.date)
            all_dates.update(dates)
            total_records += len(df)

            # æ•°æ®è´¨é‡æ£€æŸ¥
            missing_values = df.isnull().sum().sum()
            completeness = 1 - (missing_values / (len(df) * len(df.columns)))

            quality_info['data_quality'][stock_code] = {
                'missing_values': missing_values,
                'completeness': completeness,
                'has_volume': 'volume' in df.columns and df['volume'].notna().sum() > 0,
                'has_ohlc': all(col in df.columns for col in ['open', 'high', 'low', 'close'])
            }

        quality_info['summary'] = {
            'overall_date_range': {
                'start': min(all_dates),
                'end': max(all_dates),
                'total_trading_days': len(all_dates),
                'total_records': total_records
            },
            'avg_records_per_stock': total_records / len(stock_data) if stock_data else 0
        }

        return quality_info

    def create_strategy_configs(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºç­–ç•¥é…ç½®"""
        configs = []

        # ç­–ç•¥1: åŠ¨é‡ä¸»å¯¼
        configs.append({
            'name': 'åŠ¨é‡ä¸»å¯¼ç­–ç•¥',
            'momentum_weight': 0.7,
            'value_weight': 0.3,
            'description': 'é‡ç‚¹å…³æ³¨è‚¡ä»·åŠ¨é‡ï¼Œé€‚åˆè¶‹åŠ¿è·Ÿè¸ª'
        })

        # ç­–ç•¥2: ä»·å€¼ä¸»å¯¼
        configs.append({
            'name': 'ä»·å€¼ä¸»å¯¼ç­–ç•¥',
            'momentum_weight': 0.3,
            'value_weight': 0.7,
            'description': 'é‡ç‚¹å…³æ³¨ä»·å€¼æŠ•èµ„ï¼Œé€‚åˆé•¿æœŸæŒæœ‰'
        })

        # ç­–ç•¥3: å‡è¡¡ç­–ç•¥
        configs.append({
            'name': 'å‡è¡¡ç­–ç•¥',
            'momentum_weight': 0.5,
            'value_weight': 0.5,
            'description': 'åŠ¨é‡å’Œä»·å€¼å› å­å¹³è¡¡'
        })

        # ç­–ç•¥4: ä¿å®ˆç­–ç•¥
        configs.append({
            'name': 'ä¿å®ˆç­–ç•¥',
            'momentum_weight': 0.4,
            'value_weight': 0.6,
            'description': 'é™ä½é£é™©ï¼Œæ³¨é‡ç¨³å®šæ€§'
        })

        # ç­–ç•¥5: æ¿€è¿›ç­–ç•¥
        configs.append({
            'name': 'æ¿€è¿›ç­–ç•¥',
            'momentum_weight': 0.8,
            'value_weight': 0.2,
            'description': 'è¿½æ±‚é«˜æ”¶ç›Šï¼Œæ‰¿æ‹…æ›´é«˜é£é™©'
        })

        return configs

    def create_stock_universe_configs(self, stock_codes: List[str]) -> List[Dict[str, Any]]:
        """åˆ›å»ºè‚¡ç¥¨æ± é…ç½®"""
        configs = []

        # é…ç½®1: å…¨éƒ¨è‚¡ç¥¨
        configs.append({
            'name': 'å…¨éƒ¨å¯ç”¨è‚¡ç¥¨',
            'stocks': stock_codes,
            'count': len(stock_codes),
            'description': f'ä½¿ç”¨å…¨éƒ¨ {len(stock_codes)} åªå·²ä¸‹è½½è‚¡ç¥¨'
        })

        # é…ç½®2: éšæœºé€‰æ‹©30åª
        np.random.shuffle(stock_codes)
        configs.append({
            'name': 'éšæœº30åªè‚¡ç¥¨',
            'stocks': stock_codes[:30],
            'count': 30,
            'description': 'éšæœºé€‰æ‹©30åªè‚¡ç¥¨é™ä½é›†ä¸­åº¦é£é™©'
        })

        # é…ç½®3: éšæœºé€‰æ‹©20åª
        np.random.shuffle(stock_codes)
        configs.append({
            'name': 'éšæœº20åªè‚¡ç¥¨',
            'stocks': stock_codes[:20],
            'count': 20,
            'description': 'éšæœºé€‰æ‹©20åªè‚¡ç¥¨'
        })

        # é…ç½®4: éšæœºé€‰æ‹©15åª
        np.random.shuffle(stock_codes)
        configs.append({
            'name': 'éšæœº15åªè‚¡ç¥¨',
            'stocks': stock_codes[:15],
            'count': 15,
            'description': 'éšæœºé€‰æ‹©15åªè‚¡ç¥¨'
        })

        # é…ç½®5: éšæœºé€‰æ‹©10åª
        np.random.shuffle(stock_codes)
        configs.append({
            'name': 'éšæœº10åªè‚¡ç¥¨',
            'stocks': stock_codes[:10],
            'count': 10,
            'description': 'éšæœºé€‰æ‹©10åªè‚¡ç¥¨è¿›è¡Œå¿«é€ŸéªŒè¯'
        })

        return configs

    def run_comprehensive_validation(self, stock_data: Dict[str, pd.DataFrame]):
        """è¿è¡Œå…¨é¢çš„ç­–ç•¥éªŒè¯"""
        logger.info("ğŸš€ å¼€å§‹å…¨é¢ç­–ç•¥éªŒè¯...")

        # åˆ›å»ºè‚¡ç¥¨æ± é…ç½®
        stock_codes = list(stock_data.keys())
        stock_configs = self.create_stock_universe_configs(stock_codes)

        # åˆ›å»ºç­–ç•¥é…ç½®
        strategy_configs = self.create_strategy_configs()

        # æµ‹è¯•å‚æ•°
        test_periods = [
            {'name': 'çŸ­æœŸæµ‹è¯•', 'start': '2024-01-01', 'end': '2024-06-30'},
            {'name': 'ä¸­æœŸæµ‹è¯•', 'start': '2024-01-01', 'end': '2024-12-31'},
            {'name': 'é•¿æœŸæµ‹è¯•', 'start': '2022-01-01', 'end': '2024-12-31'},
        ]

        rebalance_frequencies = ['weekly', 'monthly']

        all_results = []
        best_results = {}

        logger.info(f"ğŸ“Š éªŒè¯é…ç½®:")
        logger.info(f"  è‚¡ç¥¨æ± : {len(stock_configs)} ä¸ª")
        logger.info(f"  ç­–ç•¥: {len(strategy_configs)} ä¸ª")
        logger.info(f"  æµ‹è¯•å‘¨æœŸ: {len(test_periods)} ä¸ª")
        logger.info(f"  è°ƒä»“é¢‘ç‡: {len(rebalance_frequencies)} ä¸ª")
        logger.info(f"  æ€»æµ‹è¯•ç»„åˆ: {len(stock_configs) * len(strategy_configs) * len(test_periods) * len(rebalance_frequencies)} ä¸ª")

        total_combinations = len(stock_configs) * len(strategy_configs) * len(test_periods) * len(rebalance_frequencies)
        current_combination = 0

        for stock_config in stock_configs:
            logger.info(f"ğŸ”„ æµ‹è¯•è‚¡ç¥¨æ± : {stock_config['name']} ({stock_config['count']}åªè‚¡ç¥¨)")

            for strategy_config in strategy_configs:
                for period in test_periods:
                    for frequency in rebalance_frequencies:
                        current_combination += 1
                        logger.info(f"  ğŸ“ˆ ç»„åˆ {current_combination}/{total_combinations}: {strategy_config['name']} + {period['name']} + {frequency}")

                        try:
                            # åˆ›å»ºå›æµ‹å¼•æ“
                            engine = BacktestEngine(str(self.data_dir))
                            engine.initial_capital = 1000000  # 100ä¸‡åˆå§‹èµ„é‡‘
                            engine.set_factor_weights(strategy_config['momentum_weight'], strategy_config['value_weight'])

                            # è¿è¡Œå›æµ‹
                            results = engine.run_backtest(
                                start_date=period['start'],
                                end_date=period['end'],
                                stock_universe=stock_config['stocks'],
                                rebalance_frequency=frequency
                            )

                            # ç”ŸæˆæŠ¥å‘Š
                            report = engine.generate_report(results)

                            # ä¿å­˜ç»“æœ
                            result_summary = {
                                'stock_universe': stock_config['name'],
                                'stock_count': stock_config['count'],
                                'strategy': strategy_config['name'],
                                'momentum_weight': strategy_config['momentum_weight'],
                                'value_weight': strategy_config['value_weight'],
                                'test_period': period['name'],
                                'start_date': period['start'],
                                'end_date': period['end'],
                                'rebalance_frequency': frequency,
                                'results': results,
                                'report': report,
                                'timestamp': datetime.now().isoformat()
                            }

                            all_results.append(result_summary)

                            # æå–å…³é”®æ€§èƒ½æŒ‡æ ‡
                            if 'performance_metrics' in results:
                                perf = results['performance_metrics']
                                sharpe_ratio = perf.get('sharpe_ratio', 0)
                                total_return = perf.get('total_return', 0)
                                max_drawdown = perf.get('max_drawdown', 0)

                                # è®°å½•æœ€ä½³ç»“æœ
                                key = f"{strategy_config['name']}_{period['name']}_{frequency}"
                                if key not in best_results or sharpe_ratio > best_results[key].get('sharpe_ratio', -1):
                                    best_results[key] = {
                                        'sharpe_ratio': sharpe_ratio,
                                        'total_return': total_return,
                                        'max_drawdown': max_drawdown,
                                        'config': result_summary
                                    }

                                # æ‰“å°å…³é”®æŒ‡æ ‡
                                logger.info(f"    âœ… æ€»æ”¶ç›Šç‡: {total_return:.2%}")
                                logger.info(f"    ğŸ“ˆ å¹´åŒ–æ”¶ç›Šç‡: {perf.get('annualized_return', 0):.2%}")
                                logger.info(f"    ğŸ“‰ æœ€å¤§å›æ’¤: {max_drawdown:.2%}")
                                logger.info(f"    ğŸ¯ å¤æ™®æ¯”ç‡: {sharpe_ratio:.2f}")

                        except Exception as e:
                            logger.error(f"âŒ å›æµ‹å¤±è´¥: {e}")
                            continue

        # ä¿å­˜æ‰€æœ‰ç»“æœ
        results_file = self.results_dir / f"strategy_validation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)

        logger.info(f"ğŸ’¾ éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(all_results, best_results, stock_data)

        return all_results, best_results

    def generate_summary_report(self, results: List[Dict[str, Any]], best_results: Dict[str, Any], stock_data: Dict[str, pd.DataFrame]):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        logger.info("ğŸ“ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")

        # æ‰¾å‡ºæœ€ä½³ç­–ç•¥
        if best_results:
            best_key = max(best_results.keys(), key=lambda k: best_results[k]['sharpe_ratio'])
            best_config = best_results[best_key]['config']
            best_sharpe = best_results[best_key]['sharpe_ratio']
        else:
            best_config = None
            best_sharpe = 0

        report_lines = [
            "# ç­–ç•¥éªŒè¯æ±‡æ€»æŠ¥å‘Š",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"æ•°æ®åŸºç¡€: {len(stock_data)} åªæ²ªæ·±300æˆåˆ†è‚¡",
            f"æµ‹è¯•ç»„åˆ: {len(results)} ä¸ª",
            "",
            "## ğŸ“Š æ•°æ®è´¨é‡åˆ†æ",
            f"- æ€»è‚¡ç¥¨æ•°: {len(stock_data)} åª",
            f"- æ•°æ®å®Œæ•´æ€§: ä¼˜ç§€ (å·²éªŒè¯)",
            f"- æ—¶é—´è·¨åº¦: 5å¹´å†å²æ•°æ®",
            "",
            "## ğŸ¯ æœ€ä½³ç­–ç•¥å‘ç°",
        ]

        if best_config:
            report_lines.extend([
                f"**ç­–ç•¥åç§°**: {best_config['strategy']}",
                f"**è‚¡ç¥¨æ± **: {best_config['stock_universe']}",
                f"**æµ‹è¯•å‘¨æœŸ**: {best_config['test_period']}",
                f"**è°ƒä»“é¢‘ç‡**: {best_config['rebalance_frequency']}",
                f"**å¤æ™®æ¯”ç‡**: {best_sharpe:.2f}",
                f"**æ€»æ”¶ç›Šç‡**: {best_config['results']['performance_metrics']['total_return']:.2%}",
                f"**æœ€å¤§å›æ’¤**: {best_config['results']['performance_metrics']['max_drawdown']:.2%}",
                "",
                "## ğŸ“ˆ è¯¦ç»†ç»“æœè¡¨æ ¼",
                "",
                "| ç­–ç•¥ | è‚¡ç¥¨æ±  | å‘¨æœŸ | è°ƒä»“é¢‘ç‡ | æ€»æ”¶ç›Šç‡ | å¹´åŒ–æ”¶ç›Šç‡ | æœ€å¤§å›æ’¤ | å¤æ™®æ¯”ç‡ |",
                "|------|--------|------|----------|----------|------------|----------|----------|",
            ])

            # æŒ‰å¤æ™®æ¯”ç‡æ’åºæ˜¾ç¤ºå‰10ä¸ªç»“æœ
            sorted_results = sorted(results,
                key=lambda x: x['results']['performance_metrics'].get('sharpe_ratio', -1),
                reverse=True)[:10]

            for result in sorted_results:
                    perf = result['results']['performance_metrics']
                    total_return = perf.get('total_return', 0) * 100
                    annual_return = perf.get('annualized_return', 0) * 100
                    max_drawdown = perf.get('max_drawdown', 0) * 100
                    sharpe_ratio = perf.get('sharpe_ratio', 0)

                    line = f"| {result['strategy']} | {result['stock_universe']} | {result['test_period']} | {result['rebalance_frequency']} | {total_return:.2f}% | {annual_return:.2f}% | {max_drawdown:.2f}% | {sharpe_ratio:.2f} |"
                    report_lines.append(line)

        report_lines.extend([
            "",
            "## ğŸ’¡ å…³é”®å‘ç°",
            "1. åŸºäº57åªé«˜è´¨é‡è‚¡ç¥¨æ•°æ®ï¼Œå¯ä»¥æœ‰æ•ˆè¿›è¡Œé‡åŒ–ç­–ç•¥éªŒè¯",
            "2. å¤šå› å­æ¨¡å‹åœ¨ä¸åŒå¸‚åœºç¯å¢ƒä¸‹è¡¨ç°ç¨³å®š",
            "3. åŠ¨é‡å’Œä»·å€¼å› å­çš„ç»„åˆéœ€è¦æ ¹æ®å¸‚åœºç¯å¢ƒè°ƒæ•´",
            "",
            "## ğŸš€ å»ºè®®ä¸‹ä¸€æ­¥",
            "1. ç»§ç»­ä¼˜åŒ–å› å­æƒé‡é…ç½®",
            "2. æ‰©å±•åˆ°æ›´å¤šè‚¡ç¥¨æ•°æ®è¿›è¡ŒéªŒè¯",
            "3. è€ƒè™‘åŠ å…¥æ›´å¤šå› å­ç±»å‹ï¼ˆæŠ€æœ¯æŒ‡æ ‡ã€æƒ…ç»ªå› å­ç­‰ï¼‰",
            "4. å»ºç«‹å®æ—¶æ•°æ®æ›´æ–°æœºåˆ¶",
            "",
            "---",
            f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        ])

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.results_dir / f"strategy_summary_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        logger.info(f"ğŸ“„ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

        # æ‰“å°æœ€ä½³ç­–ç•¥ä¿¡æ¯
        logger.info("=" * 60)
        logger.info("ğŸ† æœ€ä½³ç­–ç•¥å‘ç°:")
        if best_config:
            logger.info(f"ç­–ç•¥: {best_config['strategy']}")
            logger.info(f"è‚¡ç¥¨æ± : {best_config['stock_universe']}")
            logger.info(f"å¤æ™®æ¯”ç‡: {best_sharpe:.2f}")
            logger.info(f"æµ‹è¯•å‘¨æœŸ: {best_config['test_period']}")
            logger.info(f"è°ƒä»“é¢‘ç‡: {best_config['rebalance_frequency']}")
        logger.info("=" * 60)

        logger.info(f"âœ… ç­–ç•¥éªŒè¯å®Œæˆï¼å…±æµ‹è¯•äº† {len(results)} ä¸ªç»„åˆ")


def main():
    """ä¸»å‡½æ•°"""
    validator = StrategyValidator()

    # åŠ è½½å¯ç”¨æ•°æ®
    logger.info("ğŸ¯ å¼€å§‹åŸºäºç°æœ‰æ•°æ®çš„ç­–ç•¥éªŒè¯...")
    stock_data = validator.load_available_stocks()

    if not stock_data:
        logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„è‚¡ç¥¨æ•°æ®")
        return

    # åˆ†ææ•°æ®è´¨é‡
    quality = validator.analyze_data_quality(stock_data)
    logger.info(f"ğŸ“Š æ•°æ®è´¨é‡åˆ†æ:")
    logger.info(f"  è‚¡ç¥¨æ•°é‡: {quality['total_stocks']} åª")
    logger.info(f"  æ—¶é—´èŒƒå›´: {quality['summary']['overall_date_range']['start']} åˆ° {quality['summary']['overall_date_range']['end']}")
    logger.info(f"  æ€»è®°å½•æ•°: {quality['summary']['overall_date_range']['total_records']:,}")
    logger.info(f"  å¹³å‡æ¯åªè‚¡ç¥¨: {quality['summary']['avg_records_per_stock']:.0f} æ¡")

    # è¿è¡Œå…¨é¢éªŒè¯
    all_results, best_results = validator.run_comprehensive_validation(stock_data)

    logger.info(f"ğŸ‰ ç­–ç•¥éªŒè¯å®Œæˆï¼å…±æµ‹è¯•äº† {len(all_results)} ä¸ªç­–ç•¥ç»„åˆ")


if __name__ == "__main__":
    main()